# 멘토 발표 스크립트
## BroadcastComplianceAgent — 아키텍처 설명

---

## 🖼️ 1장 — 전체 시스템 흐름도

> *전체 시스템 흐름도 화면 띄우기*

---

### 오프닝

"제가 만든 시스템 전체를 한 장으로 먼저 보여드리겠습니다.

이 시스템은 **방송 광고 심의 업무를 AI로 보조하는 에이전트**입니다.
현재 심의 담당자들이 광고 문구를 검토할 때 법령집과 사례집을 수동으로 뒤져야 하는데,
그 과정을 자동화해서 판단 초안을 제공하는 것이 핵심 목표입니다."

---

### UI 레이어 설명 (파란색 노드)

"화면 왼쪽 위부터 흐름을 따라가 보겠습니다.

시스템은 **총 4개의 화면**으로 구성되어 있습니다.

첫 번째, **기준지식 관리 페이지**입니다.
관리자가 여기서 방송광고 관련 법령, 규정, 지침, 그리고 과거 심의 사례 파일을 업로드합니다.
이 데이터가 AI의 판단 근거가 되기 때문에 가장 먼저 세팅해야 하는 화면입니다.

두 번째, **심의요청 등록 페이지**입니다.
PD나 MD 담당자가 방송에서 사용할 광고 문구와 강조 자막을 여기에 입력합니다.

세 번째, **심의요청 목록 페이지**입니다.
등록된 요청들이 상태별로 쭉 나열되는 화면입니다.

네 번째, **심의 상세 페이지**가 실제 핵심 화면입니다.
심의위원이 들어와서 AI 추천을 실행하고, 최종 판정을 내리는 곳입니다."

---

### 서비스 레이어 설명 (초록색 노드)

"UI 아래에는 **서비스 레이어**가 있습니다.

`ingest_service`는 업로드된 파일을 파싱하고 청크로 분할해서 벡터 DB에 저장하는 역할을 합니다.
`review_service`는 심의 요청을 생성하고 상태를 관리합니다.
`rag_service`가 가장 중요한데, AI 추천 실행을 오케스트레이션하는 서비스입니다.
`submit_decision`은 심의자가 내린 최종 판정을 기록하는 역할을 합니다."

---

### 스토리지 레이어 설명 (빨간색 노드)

"오른쪽에 보이는 **스토리지**는 두 종류입니다.

SQLite는 구조화된 데이터, 즉 심의 요청 정보나 AI 추천 결과, 최종 판정 기록 같은 걸 저장합니다.

ChromaDB는 벡터 데이터베이스입니다.
법령과 규정, 지침, 그리고 과거 심의 사례를 각각 다른 컬렉션으로 분리해서 저장해두고,
AI가 검색할 때 유사도 기반으로 찾아옵니다."

---

### 전체 데이터 흐름 요약

"정리하면, 흐름이 크게 두 갈래입니다.

**위쪽 경로**는 지식 인덱싱 경로입니다.
관리자가 문서를 올리면 → ingest_service가 처리해서 → ChromaDB에 벡터로 저장됩니다.

**아래쪽 경로**는 심의 요청 경로입니다.
PD가 문구를 등록하면 → 목록에서 확인하고 → 심의 상세 화면에서 AI 추천을 실행합니다.
그 AI 추천 실행 부분이 바로 가운데 노란색 블록, LangGraph 노드들입니다."

---

### 전환 멘트

"그런데 저 노란색 노드들, AI가 실제로 어떻게 동작하는지가 핵심입니다.
이 부분을 좀 더 자세히 들여다보겠습니다."

> *ReviewChain 내부 노드 다이어그램으로 화면 전환*

---
---

## 🖼️ 2장 — ReviewChain 내부 LangGraph 노드

> *ReviewChain 노드 다이어그램 화면 띄우기*

---

### 도입

"이게 AI 추천의 실제 내부 구조입니다.
LangGraph라는 프레임워크를 사용해서 **6개의 노드가 그래프 형태로 연결**되어 있습니다.
단순히 LLM 한 번 호출하는 게 아니라, 스스로 검색하고, 평가하고, 부족하면 다시 검색하는
**자기 교정 루프**가 핵심입니다."

---

### PLAN 노드

"흐름은 `__start__`에서 시작해 **plan 노드**로 들어옵니다.

여기서 LLM이 광고 문구를 분석해서 위험 유형을 분류합니다.
'이 문구가 허위·과장인지, 긴급성을 유발하는지, 부당 가격 비교인지' 판단하고
그에 맞는 검색 쿼리를 생성합니다."

---

### RETRIEVE 노드

"다음은 **retrieve 노드**입니다.

plan이 만든 쿼리로 ChromaDB에서 관련 문서를 가져옵니다.
법령·규정·지침을 검색하는 `policy_search`,
과거 심의 사례를 검색하는 `case_search`,
두 도구를 상황에 따라 선택적으로 씁니다."

---

### GRADE_DOCUMENTS 노드

"검색 결과가 왔다고 해서 바로 쓰는 게 아닙니다.
**grade_documents 노드**에서 LLM이 가져온 문서들을 한 번에 평가해서
실제로 이 문구 심의에 관련 있는 청크만 걸러냅니다.

여기서 분기가 발생합니다.
관련 문서가 충분히 있으면 → generate로 넘어가고,
관련 문서가 없으면 → rewrite_query로 빠집니다."

---

### REWRITE_QUERY 노드 (재시도 루프)

"**rewrite_query 노드**는 이 시스템의 핵심 차별점입니다.

검색이 실패했을 때 그냥 포기하는 게 아니라,
'왜 검색이 안 됐을까? 쿼리를 어떻게 바꿔야 할까?'를 LLM이 스스로 판단해서
새로운 쿼리로 다시 retrieve를 실행합니다.
이 루프가 최대 3회까지 반복됩니다."

---

### GENERATE 노드

"관련 문서가 충분히 모이면 **generate 노드**로 넘어옵니다.

여기서 LLM이 법령, 규정, 지침, 사례 컨텍스트를 전부 받아서
최종 판정인 '위반소지 / 주의 / OK'와 함께
어떤 사례번호, 어떤 조항을 근거로 판단했는지를 출력합니다."

---

### GRADE_ANSWER 노드

"마지막으로 **grade_answer 노드**에서 생성된 답변의 품질을 한 번 더 검증합니다.

'사례번호를 실제로 인용했는가, 조항명이 구체적으로 명시됐는가'를 체크해서
기준을 통과하면 `__end__`로 종료하고,
미달이면 다시 rewrite_query 루프로 돌아갑니다."

---

### 클로징

"정리하면, 이 시스템은 단순한 챗봇이 아닙니다.

검색하고 → 평가하고 → 부족하면 쿼리를 고쳐서 다시 검색하고 → 생성하고 → 또 평가하는,
**스스로 품질을 높이는 루프**를 갖춘 에이전트입니다.

심의자 입장에서는 결과물에 반드시 실제 사례번호나 조항이 붙어서 나오기 때문에
'AI가 왜 이렇게 판단했는지' 근거를 바로 확인할 수 있습니다.

이상입니다. 질문 있으시면 말씀해 주세요."

---

## 📌 예상 질문 대비

| 예상 질문 | 답변 요점 |
|---|---|
| "왜 LangGraph를 썼나요?" | 노드 간 상태 공유와 조건부 루프를 코드 없이 그래프로 표현 가능. 재시도 로직이 자연스럽게 표현됨 |
| "ChromaDB를 왜 4개 컬렉션으로 나눴나요?" | 검색 범위를 문서 유형별로 제한해 노이즈 감소. 사례 vs 법령 우선순위 제어 용이 |
| "grade_documents에서 N번 호출 안 하고 배치 1회로 한 이유?" | 문서 수만큼 LLM을 직렬 호출하면 응답 시간이 N배. 배치로 묶어서 1회 호출로 대폭 단축 |
| "max_retries가 3인 근거는?" | 경험적으로 2회 재시도면 대부분 커버. 3회 초과 시 응답 시간이 사용자 대기 한계를 넘어섬 |
| "할루시네이션 방지는 어떻게 하나요?" | references에 검색된 chroma_id 기반 청크만 포함, 조항명은 컨텍스트에 있는 것만 인용하도록 프롬프트에 명시적 금지 지시 |
